{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d9331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import masp as srs\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import tqdm\n",
    "import pyrubberband as pyrb\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4806dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mls_path = '/home/ubuntu/Data/mls_spanish'\n",
    "wham_path = '/home/ubuntu/Data/wham'\n",
    "output_path = '/home/ubuntu/Data/microson_v1/'\n",
    "decoder_path = 'ku100_inear_test.mat'\n",
    "fs = 16000\n",
    "df = pd.read_csv('meta_microson_v1.csv')\n",
    "ambi_order = 10\n",
    "rims_d = .0\n",
    "maxlim = 2.\n",
    "band_centerfreqs=np.array([1000])\n",
    "\n",
    "decoder = mat73.loadmat(decoder_path)['hnm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4bd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dirs\n",
    "sets = ['train', 'dev', 'test']\n",
    "for subset in sets:\n",
    "    if not os.path.exists(pjoin(output_path, subset)):\n",
    "        os.makedirs(pjoin(output_path, subset))\n",
    "    if not os.path.exists(pjoin(pjoin(output_path, subset), 'anechoic')):\n",
    "        os.makedirs(pjoin(pjoin(output_path, subset), 'anechoic'))\n",
    "    if not os.path.exists(pjoin(pjoin(output_path, subset), 'reverberant')):\n",
    "        os.makedirs(pjoin(pjoin(output_path, subset), 'reverberant'))\n",
    "    if not os.path.exists(pjoin(pjoin(output_path, subset), 'noise')):\n",
    "        os.makedirs(pjoin(pjoin(output_path, subset), 'noise'))\n",
    "    if not os.path.exists(pjoin(pjoin(output_path, subset), 'ir')):\n",
    "        os.makedirs(pjoin(pjoin(output_path, subset), 'ir'))\n",
    "    if not os.path.exists(pjoin(pjoin(output_path, subset), 'ane_ir')):\n",
    "        os.makedirs(pjoin(pjoin(output_path, subset), 'ane_ir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df365448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we copy the metadata file to the output dir\n",
    "df.to_csv(pjoin(output_path, 'meta_microson_v1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d0b06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = df.iloc[i]\n",
    "def process(a):\n",
    "    mic = np.array(hlp.head_2_ku_ears(np.array([a.headC_x, a.headC_y, a.headC_z]),\n",
    "                                           np.array([a.headOrient_azi,a.headOrient_ele])))\n",
    "    # load noise:\n",
    "    noise, _ = sf.read(pjoin(pjoin(pjoin(wham_path, 'wham_noise'), a.wham_split), a.noise_path))\n",
    "\n",
    "    # time stretch if needed\n",
    "    if a.stretch != 0.0:\n",
    "        noise = pyrb.time_stretch(noise, a.fs_noise, a.stretch)\n",
    "\n",
    "    # extend if needed with hanning window\n",
    "    noise = np.array([hlp.extend_noise(noise[:,0], a.num_chunks * 4 * a.fs_noise, a.fs_noise),\n",
    "             hlp.extend_noise(noise[:,1], a.num_chunks * 4 * a.fs_noise, a.fs_noise)]).T\n",
    "\n",
    "    # crop 4 seconds chunk\n",
    "    noise = noise[a.chunk * 4 * a.fs_noise:(a.chunk + 1) * 4 * a.fs_noise]\n",
    "\n",
    "    # invert phase for augmentation\n",
    "    if a.phase_inv:\n",
    "        noise *= -1\n",
    "\n",
    "    # invert channels for augmentation\n",
    "    if a.lr_inv:\n",
    "        noise = noise[:, [1,0]]\n",
    "\n",
    "    noise = noise.T\n",
    "    print(a.fs_noise)\n",
    "    # load speech and crop at the 4s chunk that has more energy\n",
    "    speech_folder = pjoin(pjoin(mls_path, a.mls_split), 'audio')\n",
    "    speech, _ = sf.read(pjoin(pjoin(pjoin(speech_folder, str(a.speaker)), str(a.book)), a.speech_path))\n",
    "    print(speech.shape)\n",
    "    env = sig.fftconvolve(speech, np.ones(4*a.fs_noise), 'same')\n",
    "    idx_candidates = np.flip(np.argsort(env**2))\n",
    "    idx = idx_candidates[idx_candidates < (len(speech)-(4*a.fs_noise))][0]\n",
    "    print(idx)\n",
    "    speech = speech[idx:idx+4*a.fs_noise]\n",
    "    print(speech.shape)\n",
    "    print(noise.shape)\n",
    "    room = np.array([a.room_x, a.room_y, a.room_z])\n",
    "    rt60 = np.array([a.rt60])\n",
    "    rt60 *= 0.5#furniture absorption? \n",
    "    #snr 0, more people, more reduction -> 0.3 * rt60\n",
    "    #snr 5, less people, no rt60 reduction -> 1.0 * rt60\n",
    "    rt60 *= ((a.snr+0.3)/5.3) # people absoprtion\n",
    "    src = np.array([[a.src_x, a.src_y, a.src_z]])\n",
    "    nRec = mic.shape[0]\n",
    "\n",
    "    nSrc = src.shape[0]\n",
    "\n",
    "    head_orient = np.array([a.headOrient_azi, a.headOrient_ele])\n",
    "\n",
    "    # Compute absorption coefficients for desired rt60 and room dimensions\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "    # Small correction for sound absorption coefficients:\n",
    "    if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "        abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "\n",
    "    # Generally, we simulate up to RT60:\n",
    "    limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "    abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "    ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "    mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "    ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)\n",
    "    #hlp.plot_scene(room,np.array([a.headC_x, a.headC_y, a.headC_z]),head_orient,mic,src,perspective=\"xy\")\n",
    "    bin_ir = np.array([sig.fftconvolve(np.squeeze(mic_rirs[:,:,0, 0]), decoder[:,:,0], 'full', 0).sum(1),\n",
    "                        sig.fftconvolve(np.squeeze(mic_rirs[:,:,1, 0]), decoder[:,:,1], 'full', 0).sum(1)])\n",
    "    bin_aneIR = np.array([sig.fftconvolve(np.squeeze(ane_rirs[:,:,0, 0]), decoder[:,:,0], 'full', 0).sum(1),\n",
    "                        sig.fftconvolve(np.squeeze(ane_rirs[:,:,1, 0]), decoder[:,:,1], 'full', 0).sum(1)])\n",
    "    reverberant_src = np.array([sig.fftconvolve(speech, bin_ir[0, :], 'same'), sig.fftconvolve(speech, bin_ir[1, :], 'same')])\n",
    "    anechoic_src = np.array([sig.fftconvolve(speech, bin_aneIR[0, :], 'same'), sig.fftconvolve(speech, bin_aneIR[1, :], 'same')])\n",
    "    ini_snr = 10 * np.log10(hlp.power(reverberant_src) / hlp.power(noise))\n",
    "\n",
    "    noise_gain_db = ini_snr - a.snr\n",
    "\n",
    "    noise = noise * np.power(10, noise_gain_db/20)\n",
    "    norm_fact = np.max(np.abs(reverberant_src + noise))\n",
    "\n",
    "    anechoic_src /= norm_fact\n",
    "    noise /= norm_fact\n",
    "    reverberant_src /= norm_fact\n",
    "\n",
    "    anechoic_src *= 0.99\n",
    "    noise *= 0.99\n",
    "    reverberant_src *= 0.99\n",
    "    \n",
    "    writepath = pjoin(output_path, a.mls_split)\n",
    "    sf.write(pjoin(pjoin(writepath, 'anechoic'), os.path.splitext(a.speech_path)[0]+'.wav'), anechoic_src.T, fs, subtype='FLOAT')\n",
    "    sf.write(pjoin(pjoin(writepath, 'reverberant'), os.path.splitext(a.speech_path)[0]+'.wav'), reverberant_src.T, fs, subtype='FLOAT')\n",
    "    sf.write(pjoin(pjoin(writepath, 'noise'), os.path.splitext(a.speech_path)[0]+'.wav'), noise.T, fs, subtype='FLOAT')\n",
    "    sf.write(pjoin(pjoin(writepath, 'ir'), os.path.splitext(a.speech_path)[0]+'.wav'), bin_ir.T, fs, subtype='FLOAT')\n",
    "    sf.write(pjoin(pjoin(writepath, 'ane_ir'), os.path.splitext(a.speech_path)[0]+'.wav'), bin_aneIR.T, fs, subtype='FLOAT')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd871833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "(259360,)\n",
      "177101\n",
      "(64000,)\n",
      "(2, 64000)\n"
     ]
    }
   ],
   "source": [
    "process(df.iloc[42318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea726551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16000*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe1b918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mls_split</th>\n",
       "      <th>speaker</th>\n",
       "      <th>book</th>\n",
       "      <th>speech_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>wham_split</th>\n",
       "      <th>noise_path</th>\n",
       "      <th>chunk</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>len_s</th>\n",
       "      <th>...</th>\n",
       "      <th>headC_y</th>\n",
       "      <th>headC_z</th>\n",
       "      <th>src_x</th>\n",
       "      <th>src_y</th>\n",
       "      <th>src_z</th>\n",
       "      <th>headOrient_azi</th>\n",
       "      <th>headOrient_ele</th>\n",
       "      <th>snr</th>\n",
       "      <th>lr_inv</th>\n",
       "      <th>stretch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42317</th>\n",
       "      <td>train</td>\n",
       "      <td>10246</td>\n",
       "      <td>12118</td>\n",
       "      <td>10246_12118_001034.flac</td>\n",
       "      <td>F</td>\n",
       "      <td>tr</td>\n",
       "      <td>20qa010z_0.2521_20fo010p_-0.2521.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.112125</td>\n",
       "      <td>...</td>\n",
       "      <td>2.56667</td>\n",
       "      <td>1.517522</td>\n",
       "      <td>5.373512</td>\n",
       "      <td>3.476149</td>\n",
       "      <td>1.517522</td>\n",
       "      <td>18.189901</td>\n",
       "      <td>4.66479</td>\n",
       "      <td>3.648416</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mls_split  speaker   book              speech_path gender wham_split  \\\n",
       "42317     train    10246  12118  10246_12118_001034.flac      F         tr   \n",
       "\n",
       "                                 noise_path  chunk  num_chunks      len_s  \\\n",
       "42317  20qa010z_0.2521_20fo010p_-0.2521.wav      1           3  11.112125   \n",
       "\n",
       "       ...  headC_y   headC_z     src_x     src_y     src_z  headOrient_azi  \\\n",
       "42317  ...  2.56667  1.517522  5.373512  3.476149  1.517522       18.189901   \n",
       "\n",
       "       headOrient_ele       snr  lr_inv  stretch  \n",
       "42317         4.66479  3.648416    True      0.0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['speech_path']=='10246_12118_001034.flac']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
