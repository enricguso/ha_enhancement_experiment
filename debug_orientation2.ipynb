{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "sources_pos= hlp.place_on_circle(head_pos,1,90)\n",
    "head_orient = np.array([180, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 16000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7786e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a45b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "decoder_KU100woHAinear = mat73.loadmat('ku100_inear_test.mat')['hnm']\n",
    "\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture=hlp.generate_scenes(sources_sigs,levels,mic_rirs,decoder_KU100woHAinear)\n",
    "Audio(mixture, rate=fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4933ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_orient = np.array([90, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 16000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d)\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "decoder_KU100woHAinear = mat73.loadmat('ku100_inear_test.mat')['hnm']\n",
    "\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture=hlp.generate_scenes(sources_sigs,levels,mic_rirs,decoder_KU100woHAinear)\n",
    "Audio(mixture, rate=fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1e1c2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ha_enhancement_experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8215c859ffbfdb512c0a2f32b6e82e13dc69a4ba1fc2f2a346e445a7cb9f022f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
