{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979138dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import masp as srs\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import tqdm\n",
    "import pyrubberband as pyrb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE DEFINE THE CHUNK LENGHT TO 4 SECONDS (DEFAULT TO USING SUDO-RM-RF)\n",
    "# SET PATHS:\n",
    "mls_path = '/home/ubuntu/Data/mls_spanish'\n",
    "wham_path = '/home/ubuntu/Data/wham'\n",
    "output_path = '/home/ubuntu/Data/ha_scenes_sounds/'\n",
    "fs = 16000\n",
    "fs_n = 'wav16k'\n",
    "mode = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_chunks_by_duration(seconds_list):\n",
    "    # Files that can reasonably be padded will be padded.\n",
    "    # Otherwise we crop\n",
    "    out = []\n",
    "    chunk = []\n",
    "    low_bound = np.array([(x+1)*2 for x in list(range(11))])   \n",
    "    hi_bound = np.array([(x+2)*2 for x in list(range(11))])\n",
    "    n_chunks = np.repeat(np.array([x+1 for x in list(range(6))]), 2)\n",
    "    n_chunks = n_chunks[:len(low_bound)]\n",
    "    for s in seconds_list:\n",
    "        x = n_chunks[np.argmax(np.logical_and(s > low_bound, s < hi_bound))]\n",
    "        out.append(x)\n",
    "        chunk.append(list(range(x)))\n",
    "    return out, chunk   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1faef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "noise_info = []\n",
    "for split in ['tr', 'cv', 'tt']:\n",
    "    split_path = pjoin(pjoin(wham_path, 'wham_noise'), split)\n",
    "    for audio_path in  tqdm.tqdm(os.listdir(split_path)):\n",
    "        audio, fs = sf.read(pjoin(split_path, audio_path))\n",
    "        noise_info.append({'split': split, 'audio_path': pjoin(split_path, audio_path), 'size_mb': os.stat(pjoin(split_path, audio_path)).st_size / (1024 * 1024), 'fs': fs, 'shape':audio.shape})\n",
    "        \n",
    "\n",
    "ometa = pd.read_csv(pjoin(mls_path, 'metainfo.txt'), sep= '|')\n",
    "ometa.columns = ometa.columns.str.strip()\n",
    "ometa['PARTITION'] = ometa['PARTITION'].str.strip()\n",
    "\n",
    "info = []\n",
    "for split in ['train', 'test', 'dev']:\n",
    "    split_path = pjoin(pjoin(mls_path, split), 'audio')\n",
    "    speakers = os.listdir(split_path)\n",
    "    for speaker in speakers:\n",
    "        speaker_path = pjoin(split_path, speaker)\n",
    "        books = os.listdir(speaker_path)\n",
    "        for book in books:\n",
    "            book_path = pjoin(speaker_path, book)\n",
    "            audio_paths = os.listdir(book_path)\n",
    "            for audio_path in audio_paths:\n",
    "                gender = list(ometa[ometa['SPEAKER']==int(speaker)]['GENDER'])[0].strip()\n",
    "                info.append({'split': split, 'speaker': speaker, 'book': book, 'audio_path': pjoin(book_path, audio_path), 'gender': gender})\n",
    "\n",
    "df_s = pd.DataFrame(info)\n",
    "df_n = pd.DataFrame(noise_info)\n",
    "\n",
    "\n",
    "lens = list(df_n['shape'])\n",
    "\n",
    "df_n.iloc[0]['audio_path']\n",
    "\n",
    "df_s.to_pickle(\"mls_info.pkl\")\n",
    "df_n.to_pickle(\"wham_info.pkl\")\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = pd.read_pickle(\"mls_info.pkl\")\n",
    "df_n = pd.read_pickle(\"wham_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_wham_train_set(tr, speech_len, fs):\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    # Store lenght (in samples and seconds) from shape\n",
    "    tr.insert(2, \"len_samp\", [x[0] for x in list(tr['shape'])], True)\n",
    "    tr.insert(2, \"len_s\", [x[0]/fs for x in list(tr['shape'])], True)\n",
    "    \n",
    "    # Assign a number of chunks. Chunks from [2,4]s are expanded to one 4s chunk. \n",
    "    # Chunks from [4,6]s are cropped to one 4s chunk\n",
    "    nchunks, chunk = assign_chunks_by_duration(list(tr['len_s']))\n",
    "    tr.insert(2, \"num_chunks\", nchunks, True)\n",
    "    lentr = len(tr)\n",
    "    tr = tr.reindex(tr.index.repeat(tr.num_chunks))\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"chunk\", [item for sublist in chunk for item in sublist], True)\n",
    "    # One copy will have phase inversion (*(-1))\n",
    "    L = [False, True]\n",
    "    tr = (pd.DataFrame(np.repeat(tr.values, 2, axis=0), columns=tr.columns)\n",
    "               .assign(phase_inv = np.tile(L, len(tr))))\n",
    "    # The other copy will have a swap of left and right channels\n",
    "    tr = (pd.DataFrame(np.repeat(tr.values, 2, axis=0), columns=tr.columns)\n",
    "               .assign(lr_inv = np.tile(L, len(tr))))\n",
    "    # The rest of utterances we have to augment will randomly time-streched\n",
    "    stretch_utt = speech_len - len(tr)\n",
    "    stretch  = np.concatenate((np.zeros(len(tr)), np.random.uniform(low=0.9, high=1.1, size=(stretch_utt))))\n",
    "    tr = pd.concat([tr, tr[0:stretch_utt]])\n",
    "    tr.insert(11, \"stretch\", stretch, True)\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr = tr.rename(columns={'audio_path': 'noise_path'})\n",
    "    tr = tr.rename(columns={'split': 'wham_split'})\n",
    "    return tr\n",
    "\n",
    "def crop_wham_test_set(tr, speech_len, fs):\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"len_samp\", [x[0] for x in list(tr['shape'])], True)\n",
    "    tr.insert(2, \"len_s\", [x[0]/fs for x in list(tr['shape'])], True)\n",
    "    tr = tr[tr.len_s > 4.]\n",
    "    tr = tr[:speech_len]\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"chunk\", [0]*len(tr))\n",
    "    tr.insert(3, \"num_chunks\", [1]*len(tr))\n",
    "    tr.insert(9, \"phase_inv\", [False]*len(tr))\n",
    "    tr.insert(10, \"lr_inv\", [False]*len(tr))\n",
    "    tr.insert(11, \"stretch\", np.zeros(len(tr)))\n",
    "    tr = tr.rename(columns={'audio_path': 'noise_path'})\n",
    "    tr = tr.rename(columns={'split': 'wham_split'})\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = augment_wham_train_set(df_n[df_n['split']=='tr'], len(df_s[df_s['split']=='train']), fs)\n",
    "cv = crop_wham_test_set(df_n[df_n['split']=='cv'], len(df_s[df_s['split']=='dev']), fs)\n",
    "tt = crop_wham_test_set(df_n[df_n['split']=='tt'], len(df_s[df_s['split']=='test']), fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_wham = pd.concat([tr, tt, cv], axis=0)\n",
    "aug_wham = aug_wham.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf439137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we merge the augmented wham metadata with the MLS-spanish metadata\n",
    "df = pd.concat([df_s, aug_wham], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5159f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc385f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "\n",
    "head_orient_azi = np.zeros(len(df))\n",
    "head_orient_ele = np.zeros(len(df))\n",
    "angle = np.random.uniform(low = -45, high = 45, size = len(df))\n",
    "dist = np.random.uniform(low = 0.5, high = 3, size = len(df))\n",
    "snr = np.random.uniform(low = -6, high = 6, size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_x = np.random.uniform(low = 2., high = 30., size = len(df))\n",
    "room_y = np.random.uniform(low = 2., high = 30., size = len(df))\n",
    "room_z = np.random.uniform(low = 2.5, high = 5., size = len(df))\n",
    "np.random.shuffle(room_x)\n",
    "np.random.shuffle(room_y)\n",
    "np.random.shuffle(room_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2bebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t60s =  np.random.uniform(low = .1, high = 1., size = len(df))\n",
    "t60s = np.sort(t60s)\n",
    "volumes = room_x * room_y * room_z\n",
    "volumes = np.sort(volumes)\n",
    "dist = np.sort(dist)\n",
    "perm = np.random.permutation(len(volumes))\n",
    "room_x = room_x[perm]\n",
    "room_y = room_y[perm]\n",
    "room_z = room_z[perm]\n",
    "dist = dist[perm]\n",
    "t60s = t60s[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pos = []\n",
    "for k in range(len(room_x)):\n",
    "    head_pos.append(np.array([np.random.uniform(low = 0.35*room_x[k], high = 0.65*room_x[k]),\n",
    "                        np.random.uniform(low = 0.35*room_y[k], high = 0.65*room_y[k]),\n",
    "                        np.random.uniform(low = 1., high = 2.)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pos = np.array(head_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "room = np.array((room_x, room_y, room_z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e658060",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = []\n",
    "for k in range(len(room_x)):\n",
    "    new_target_pos, new_head_pos = hlp.place_on_circle_in_room(head_pos[k], dist[k], angle[k], room[k])\n",
    "    head_pos[k] = new_head_pos\n",
    "    target_pos.append(new_target_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = np.squeeze(np.array(target_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46490d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks:\n",
    "np.all(target_pos < room) # all targets are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(head_pos < room) # all heads are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b94571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's check the ears:\n",
    "ears_pos = []\n",
    "for k in range(head_pos.shape[0]):\n",
    "    ears_pos.append(np.array(hlp.head_2_ku_ears(head_pos[k], np.array([0,0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6730c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ears_pos = np.array(ears_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ears_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 0, :] < room) # all left ears are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 1, :] < room) # all right are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40dc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final MINIMUM distance between head and target (check we don't have an intra-craneal target)\n",
    "min(np.sqrt(np.sum((target_pos - head_pos)**2, axis=1))) > 0.0875 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of ears against a wall\n",
    "min ( min(room[:, 0] - ears_pos[:, 0, 0]), min(room[:, 0] - ears_pos[:, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c004747",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 1] - ears_pos[:, 0, 1]), min(room[:, 1] - ears_pos[:, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43170436",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 2] - ears_pos[:, 0, 2]), min(room[:, 2] - ears_pos[:, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7901055",
   "metadata": {},
   "outputs": [],
   "source": [
    "room.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of targets against a wall\n",
    "min(min(room[:, 0] - target_pos[:, 0]), min(room[:, 1] - target_pos[:, 1]), min(room[:, 2] - target_pos[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(17, \"room_x\", room[:, 0])\n",
    "df.insert(18, \"room_y\", room[:, 1])\n",
    "df.insert(19, \"room_z\", room[:, 2])\n",
    "df.insert(20, \"rt60\", t60s)\n",
    "df.insert(21, \"headC_x\", head_pos[:,0])\n",
    "df.insert(22, \"headC_y\", head_pos[:,1])\n",
    "df.insert(23, \"headC_z\", head_pos[:,2])\n",
    "df.insert(24, \"src_x\", target_pos[:,0])\n",
    "df.insert(25, \"src_y\", target_pos[:,1])\n",
    "df.insert(26, \"src_z\", target_pos[:,2])\n",
    "df.insert(27, \"orient_azi\", head_orient_azi)\n",
    "df.insert(28, \"orient_ele\", head_orient_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa9655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add rotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
